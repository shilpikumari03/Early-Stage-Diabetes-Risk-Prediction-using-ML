{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6509a759",
   "metadata": {},
   "source": [
    "## Model Building"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34a7eb69",
   "metadata": {},
   "source": [
    "##### We will be building ML models like Logistic regression, Neural network, Support vector Machine(SVM) and Decision tree and we will be doing hyperparameter tuning to predict the chance of diabetes. We will be using Recall as a performance metric to judge our models.\n",
    "\n",
    "##### We choose Recall as a performance metric to judge our models as we have to give priority to FALSE NEGATIVES. FN are the cases when our model predicts that there are no chances of Diabetes but in reality there is a high risk of getting it. I such a senario the patient is at the risk of loosing their life as he might not be aware that he has to control his surgar intake."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e407ee8a",
   "metadata": {},
   "source": [
    "### Loading all the required libraries \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7287bac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.executable\n",
    "!pip install xgboost\n",
    "!pip install tensorflow\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from __future__ import print_function\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, precision_score, recall_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "from pandas import MultiIndex, Int64Index\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "# fix random seed for reproducibility\n",
    "np.random.seed(1)\n",
    "tf.random.set_seed(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00446d60",
   "metadata": {},
   "source": [
    "### Loading the processed training and test datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f54d490e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.read_csv('C:/Users/shilp/Downloads/X_train.csv') \n",
    "y_train = pd.read_csv('C:/Users/shilp/Downloads/y_train.csv') \n",
    "X_test = pd.read_csv('C:/Users/shilp/Downloads/X_test.csv') \n",
    "y_test = pd.read_csv('C:/Users/shilp/Downloads/y_test.csv') "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "543eceea",
   "metadata": {},
   "source": [
    "### Building a dataframe to store our models performance metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "264e3a35",
   "metadata": {},
   "outputs": [],
   "source": [
    "performance = pd.DataFrame({\"model\": [], \"Accuracy\": [], \"Precision\": [], \"Recall\": [], \"F1\": []})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45ea1ebc",
   "metadata": {},
   "source": [
    "### Implementing Logistic Regression model with hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cb5de7d",
   "metadata": {},
   "source": [
    "##### Using Randomized search to find the best parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab531c5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'penalty': ['l1', 'l2'], \n",
    "              'C': [0.001, 0.01, 0.1, 1, 10, 100],\n",
    "              'solver': ['liblinear', 'saga'],\n",
    "              'l1_ratio': [0.25, 0.5, 0.75],\n",
    "             'max_iter': np.arange(800, 1200)\n",
    "             }\n",
    "\n",
    "# Perform Randomized Search CV to find the best hyperparameters\n",
    "best_lregression = RandomizedSearchCV(estimator=LogisticRegression(random_state=0, solver='saga'),\n",
    "                                      scoring='recall', \n",
    "                                      param_distributions=param_grid, \n",
    "                                      cv=10, \n",
    "                                      verbose=0, \n",
    "                                      return_train_score=True, \n",
    "                                      n_iter=500, \n",
    "                                      n_jobs=-1)\n",
    "best_lregression.fit(X_train, y_train)\n",
    "\n",
    "# Print the best parameters found through Randomized Search CV\n",
    "print(f\"Best parameters found through Randomized Search CV: {best_lregression.best_params_}\")\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1771ba78",
   "metadata": {},
   "source": [
    "##### Performing GridSearch over a close range of parameters that we got from Randomized search to find the best parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "831cea68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the parameter grid for Grid Search CV\n",
    "param_grid = { \n",
    "    'solver': [best_lregression.best_params_['solver']],\n",
    "    'penalty': [best_lregression.best_params_['penalty']],\n",
    "    'C': [0.1, 1, 10],\n",
    "    'max_iter': np.arange(750,950)\n",
    "}\n",
    "\n",
    "# Perform Grid Search CV with the best parameters from Randomized Search CV\n",
    "grid_lregression = GridSearchCV(estimator=LogisticRegression(random_state=0, solver=best_lregression.best_params_['solver']),\n",
    "                                param_grid=param_grid,\n",
    "                                scoring='recall',\n",
    "                                cv=10,\n",
    "                                n_jobs=-1)\n",
    "grid_lregression.fit(X_train, y_train)\n",
    "\n",
    "# Print the best parameters found through Grid Search CV\n",
    "print(f\"Best parameters found through Grid Search CV: {grid_lregression.best_params_}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b841641",
   "metadata": {},
   "source": [
    "##### Storing the performance metrics in the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "719b45df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model using the best parameters found through Grid Search CV \n",
    "c_matrix = confusion_matrix(y_test, grid_lregression.predict(X_test))\n",
    "TP = c_matrix[1][1]\n",
    "TN = c_matrix[0][0]\n",
    "FP = c_matrix[0][1]\n",
    "FN = c_matrix[1][0]\n",
    "performance = pd.concat([performance, pd.DataFrame({'model': \"LR\", \n",
    "                                                     'Accuracy': [(TP+TN)/(TP+TN+FP+FN)], \n",
    "                                                     'Precision': [TP/(TP+FP)], \n",
    "                                                     'Recall': [TP/(TP+FN)], \n",
    "                                                     'F1': [2*TP/(2*TP+FP+FN)]\n",
    "                                                    }, index=[0])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cc80e4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d59e4e93",
   "metadata": {},
   "source": [
    "### Implementing SVM model with hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2238831d",
   "metadata": {},
   "source": [
    "##### Using Randomized search to find the best parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fadadf49",
   "metadata": {},
   "outputs": [],
   "source": [
    "score_measure = \"recall\"\n",
    "kfolds = 5\n",
    "\n",
    "param_grid = {\n",
    "    'C': np.arange(1,25),   \n",
    "    'gamma': ['scale','auto'],\n",
    "    'kernel':['linear','rbf','poly']\n",
    "}\n",
    "\n",
    "svm = SVC()\n",
    "rand_search = RandomizedSearchCV(estimator = svm, param_distributions=param_grid, cv=kfolds, n_iter=140,\n",
    "                           scoring=score_measure, verbose=1, n_jobs=-1, \n",
    "                           return_train_score=True)\n",
    "\n",
    "_ = rand_search.fit(X_train, y_train)\n",
    "\n",
    "print(f\"The best {score_measure} score is {rand_search.best_score_}\")\n",
    "print(f\"... with parameters: {rand_search.best_params_}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dba7e36",
   "metadata": {},
   "source": [
    "##### Performing GridSearch over a close range of parameters that we got from Randomized search to find the best parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dc23035",
   "metadata": {},
   "outputs": [],
   "source": [
    "score_measure = \"recall\"\n",
    "kfolds = 5\n",
    "\n",
    "C = rand_search.best_params_['C']\n",
    "gamma = rand_search.best_params_['gamma']\n",
    "kernel = rand_search.best_params_['kernel']\n",
    "\n",
    "param_grid = {\n",
    "    'C': np.arange(C-2,C+2),  \n",
    "    'gamma': [gamma],\n",
    "    'kernel': [kernel]\n",
    "    \n",
    "}\n",
    "\n",
    "svm1 = SVC()\n",
    "grid_search = GridSearchCV(estimator = svm1, param_grid=param_grid, cv=kfolds, \n",
    "                           scoring=score_measure, verbose=1, n_jobs=-1, # n_jobs=-1 will utilize all available CPUs \n",
    "                           return_train_score=True)\n",
    "\n",
    "_ = grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(f\"The best {score_measure} score is {grid_search.best_score_}\")\n",
    "print(f\"... with parameters: {grid_search.best_params_}\")\n",
    "\n",
    "bestprecision_SVM = grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7b7b2c8",
   "metadata": {},
   "source": [
    "##### Storing the performance metrics in the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad2e0a00",
   "metadata": {},
   "outputs": [],
   "source": [
    "c_matrix = confusion_matrix(y_test, grid_search.predict(X_test))\n",
    "TP = c_matrix[1][1]\n",
    "TN = c_matrix[0][0]\n",
    "FP = c_matrix[0][1]\n",
    "FN = c_matrix[1][0]\n",
    "performance = pd.concat([performance, pd.DataFrame({'model':\"SVM\", \n",
    "                                                    'Accuracy': [(TP+TN)/(TP+TN+FP+FN)], \n",
    "                                                    'Precision': [TP/(TP+FP)], \n",
    "                                                    'Recall': [TP/(TP+FN)], \n",
    "                                                    'F1': [2*TP/(2*TP+FP+FN)]\n",
    "                                                     }, index=[0])])\n",
    "performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fd2981f",
   "metadata": {},
   "source": [
    "### Implementing Decision Tree model with hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d173302a",
   "metadata": {},
   "source": [
    "##### Using Randomized search to find the best parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fc198fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "score_measure = \"recall\"\n",
    "kfolds = 5\n",
    "\n",
    "param_grid = {\n",
    "    'min_samples_split': np.arange(2,50),  \n",
    "    'min_samples_leaf': np.arange(1,50),\n",
    "    'min_impurity_decrease': np.arange(0.0001, 0.01, 0.0005),\n",
    "    'max_leaf_nodes': np.arange(5, 50), \n",
    "    'max_depth': np.arange(1,20), \n",
    "    'criterion': ['gini', 'entropy'],\n",
    "}\n",
    "\n",
    "dtree = DecisionTreeClassifier()\n",
    "rand_search = RandomizedSearchCV(estimator=dtree, param_distributions=param_grid, cv=kfolds, n_iter=500,\n",
    "                                 scoring=score_measure, verbose=1, n_jobs=-1, # n_jobs=-1 will utilize all available CPUs \n",
    "                                 return_train_score=True)\n",
    "\n",
    "_ = rand_search.fit(X_train, y_train)\n",
    "\n",
    "print(f\"The best {score_measure} score is {rand_search.best_score_}\")\n",
    "print(f\"... with parameters: {rand_search.best_params_}\")\n",
    "\n",
    "bestPrecTree = rand_search.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "817e7b40",
   "metadata": {},
   "source": [
    "##### Performing GridSearch over a close range of parameters that we got from Randomized search to find the best parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ecf1377",
   "metadata": {},
   "outputs": [],
   "source": [
    "score_measure = \"recall\"\n",
    "kfolds = 5\n",
    "\n",
    "param_grid = {\n",
    "    'min_samples_split': np.arange(26,36),  \n",
    "    'min_samples_leaf': np.arange(8,16),\n",
    "    'min_impurity_decrease': np.arange( 0.0005, 0.0010, 0.0020),\n",
    "    'max_leaf_nodes': [10,30], \n",
    "    'max_depth': [5,15], \n",
    "    'criterion': ['entropy']\n",
    "}\n",
    "\n",
    "\n",
    "dtree = DecisionTreeClassifier()\n",
    "grid_search = GridSearchCV(estimator = dtree, param_grid=param_grid, cv=kfolds, \n",
    "                           scoring=score_measure, verbose=1, n_jobs=-1,  # n_jobs=-1 will utilize all available CPUs \n",
    "                           return_train_score=True)\n",
    "\n",
    "_ = grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(f\"The best {score_measure} score is {grid_search.best_score_}\")\n",
    "print(f\"... with parameters: {grid_search.best_params_}\")\n",
    "\n",
    "bestPrecisionTree = grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66773553",
   "metadata": {},
   "source": [
    "##### Storing the performance metrics in the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7658ae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "c_matrix = confusion_matrix(y_test, grid_search.predict(X_test))\n",
    "TP = c_matrix[1][1]\n",
    "TN = c_matrix[0][0]\n",
    "FP = c_matrix[0][1]\n",
    "FN = c_matrix[1][0]\n",
    "performance = pd.concat([performance, pd.DataFrame({'model':\"Decision Tree\", \n",
    "                                                    'Accuracy': [(TP+TN)/(TP+TN+FP+FN)], \n",
    "                                                    'Precision': [TP/(TP+FP)], \n",
    "                                                    'Recall': [TP/(TP+FN)], \n",
    "                                                    'F1': [2*TP/(2*TP+FP+FN)]\n",
    "                                                     }, index=[0])])\n",
    "performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81fb1b0f",
   "metadata": {},
   "source": [
    "### Implementing Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8f2aa3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "score_measure = \"recall\"\n",
    "kfolds = 5\n",
    "\n",
    "param_grid = {\n",
    "    'hidden_layer_sizes': [ (50,), (70,),(50,30), (40,20), (60,40, 20)],\n",
    "    'activation': ['logistic', 'tanh', 'relu'],\n",
    "    'solver': ['adam', 'sgd'],\n",
    "    'alpha': [0, .2, .5, .7, 1],\n",
    "    'learning_rate': ['constant', 'invscaling', 'adaptive'],\n",
    "    'learning_rate_init': [0.001, 0.01, 0.1, 0.2],\n",
    "    'max_iter': [1000]\n",
    "}\n",
    "\n",
    "ann = MLPClassifier()\n",
    "grid_search = RandomizedSearchCV(estimator = ann, param_distributions=param_grid, cv=kfolds, n_iter=500,\n",
    "                           scoring=score_measure, verbose=1, n_jobs=-1,  # n_jobs=-1 will utilize all available CPUs \n",
    "                           return_train_score=True)\n",
    "\n",
    "_ = grid_search.fit(X_train, y_train)\n",
    "\n",
    "bestRecallTree = grid_search.best_estimator_\n",
    "\n",
    "print(grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33b9885b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "y_pred = bestRecallTree.predict(X_test)\n",
    "\n",
    "c_matrix = confusion_matrix(y_test, y_pred)\n",
    "TP = c_matrix[1][1]\n",
    "TN = c_matrix[0][0]\n",
    "FP = c_matrix[0][1]\n",
    "FN = c_matrix[1][0]\n",
    "performance = pd.concat([performance, pd.DataFrame({'model':\"Neural Network Randomized search\", \n",
    "                                                    'Accuracy': [(TP+TN)/(TP+TN+FP+FN)],  \n",
    "                                                    'Recall': [TP/(TP+FN)], \n",
    "                                                    'F1': [2*TP/(2*TP+FP+FN)]\n",
    "                                                     }, index=[0])])\n",
    "performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5df95e80",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "score_measure = \"recall\"\n",
    "kfolds = 5\n",
    "\n",
    "param_grid = {\n",
    "    'hidden_layer_sizes': [ (30,), (50,), (70,), (90,)],\n",
    "    'activation': ['tanh', 'relu'],\n",
    "    'solver': ['adam'],\n",
    "    'alpha': [.5, .7, 1],\n",
    "    'learning_rate': ['adaptive', 'invscaling'],\n",
    "    'learning_rate_init': [0.005, 0.01, 0.15],\n",
    "    'max_iter': [1000]\n",
    "}\n",
    "\n",
    "ann = MLPClassifier()\n",
    "grid_search = GridSearchCV(estimator = ann, param_grid=param_grid, cv=kfolds, \n",
    "                           scoring=score_measure, verbose=1, n_jobs=-1,  # n_jobs=-1 will utilize all available CPUs \n",
    "                           return_train_score=True)\n",
    "\n",
    "_ = grid_search.fit(X_train, y_train)\n",
    "\n",
    "bestRecallTree = grid_search.best_estimator_\n",
    "\n",
    "print(grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d340827a",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = bestRecallTree.predict(X_test)\n",
    "\n",
    "c_matrix = confusion_matrix(y_test, y_pred)\n",
    "TP = c_matrix[1][1]\n",
    "TN = c_matrix[0][0]\n",
    "FP = c_matrix[0][1]\n",
    "FN = c_matrix[1][0]\n",
    "performance = pd.concat([performance, pd.DataFrame({'model':\"Neural Network Grid search\", \n",
    "                                                    'Accuracy': [(TP+TN)/(TP+TN+FP+FN)],  \n",
    "                                                    'Recall': [TP/(TP+FN)], \n",
    "                                                    'F1': [2*TP/(2*TP+FP+FN)]\n",
    "                                                     }, index=[0])])\n",
    "performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97cb07d0",
   "metadata": {},
   "source": [
    "#### Deep Neural Network Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f307724e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras.backend as K\n",
    "\n",
    "# define recall function as a member function of the Model class\n",
    "class Metrics(keras.callbacks.Callback):\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.recall = []\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        y_pred = self.model.predict(X_test)\n",
    "        y_pred = np.round(y_pred)\n",
    "        _recall = recall_score(y_test, y_pred)\n",
    "        self.recall.append(_recall)\n",
    "        print(\"val_recall:\",_recall)\n",
    "\n",
    "def recall(y_test, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_test * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_test, 0, 1)))\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    return recall\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d04c5f40",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "%%time\n",
    "\n",
    "# create model stucture\n",
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.Input(16))\n",
    "model.add(keras.layers.Dense(10, activation='relu',kernel_initializer= tf.keras.initializers.GlorotNormal()))\n",
    "model.add(keras.layers.Dense(10, activation='relu', kernel_initializer= tf.keras.initializers.GlorotNormal()))\n",
    "model.add(keras.layers.Dense(10, activation='relu', kernel_initializer= tf.keras.initializers.GlorotNormal()))\n",
    "model.add(keras.layers.Dense(1, activation='sigmoid')) \n",
    "\n",
    "# compile the model with the custom loss function\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=[recall])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f5b24e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# fit the model\n",
    "history = model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=20, batch_size=100, callbacks=[Metrics()])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07df0656",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# fit the model\n",
    "history = model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=20, batch_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3500ad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "y_pred = (y_pred > 0.5)\n",
    "\n",
    "c_matrix = confusion_matrix(y_test, y_pred)\n",
    "TP = c_matrix[1][1]\n",
    "TN = c_matrix[0][0]\n",
    "FP = c_matrix[0][1]\n",
    "FN = c_matrix[1][0]\n",
    "performance = pd.concat([performance, pd.DataFrame({'model':\"Deep Neural Network\", \n",
    "                                                    'Accuracy': [(TP+TN)/(TP+TN+FP+FN)],  \n",
    "                                                    'Recall': [TP/(TP+FN)], \n",
    "                                                    'F1': [2*TP/(2*TP+FP+FN)]\n",
    "                                                     }, index=[0])])\n",
    "performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92f27635",
   "metadata": {},
   "source": [
    "#### Looking at the performance metric dataframe we can see that the highest recall score of 100 percent is of SVM and Neural Network model. Although these model  has the low accuracy, precision and F1 score.  We know that no model can predict anything with 100 percent accuracy and the same goes for these models also.\n",
    "\n",
    "#### Overall we can say that DNN model is the best model for predicting that if a person is at the risk of getting Diabetes as it has a recall score of 98.9 percent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b4174e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61a4fb41",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b33da9a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cea51713",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
